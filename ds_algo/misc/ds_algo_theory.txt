******************** BASICS ******************
Reading and writing files and data from memory (RAM) is faster than storage
Applications like chrome, music player etc are  stored on storage but runs on memory
Each variable is represented via 32 bits/64 bits and an address is assigned to it.
1byte = 8bits | memory(RAM) is a tape of bytes
Main-memory/primary storage - direct accessible by the CPU | e.g: ROM,RAM and cache
Volatile memory - deleted after when power is lost
Non-volatile - ROM, storage
//ROM : computer boot code is stored , can't be erased
//Cache: much faster than RAM bcoz it is located closer to CPU but size less than RAM 
//RAM(memory) = code + stack(function calls and local variables) + global variables + heap(Objects) + Eventloop(synchronous message queue)
Heap is a name to denote a large (mostly unstructured) region of memory.
Once a message appears in the event loop then JS pauses the execution.after all the messages are addressed the JS execution resumes.
Eventloop  - message is removed from the queue and its corresponding callback function is called on the stack with the message as param.
Other messages has to wait until the current function is done executing. A downside of this model is that if a message takes too long to
complete, the web application is unable to process user interactions like click or scroll.
Hence it is recommended to process data intensive and network operations using web workers. 
//Avoid Recursion while things can be done via loops and DP
Recursion vs loops: 
Recursion - call stack is not emptied until the execution on the last element is completed | can cause stack overflow 
loops - call stack is emptied immediately after the execution on that particular element
Time complexity for loops : O(n), Time complexity for Recursion : O(n)
Space complexity for loops : O(1), Space complexity for Recursion : O(n)

***********************  DATA STRUCTURES  ******************
DATA STRUCTURES = different ways of storing data on a computer
which data stucture to use: depends on the type of data to be stored, cost of operations, memory
Abstract data types: we only talk about features/operations and not Implementation

//Lists: Linear data structures - Abstract data type
1)Arrays: contigous memory allocation | for dealing with static data (fixed size)
Insert/delete: O(n) | random Access of element - constant time (because of efficient indexing)
Dynamic array - copy elements of smaller array into bigger array and delete smaller array | O(n)
//JS Array built-in functions
array.push	    O(1)	Insert element to the end of the array
array.pop	    O(1)	Remove element to the end of the array
array.shift	    O(n)	Remove element to the beginning of the array
array.unshift	O(n)	Insert element(s) to the beginning of the array
array.slice	    O(n)	Returns a copy of the array from beginning to end.
array.splice	O(n)	Changes (add/remove) the array


//iteration in JS
https://thecodebarbarian.com/for-vs-for-each-vs-for-in-vs-for-of-in-javascript.html
*For, foreach and for/in looping constructs give you access to the index in the array and actual element 
*for of only gives access to element and not index | for (const [i, v] of arr.entries()) { console.log(i, v); // Prints "0 a", "1 b", "2 c" }
*for, for/in, and for/of retain the outside scope's value of this, but the forEach() callback will have a different this unless you use an arrow function.
*Avoid using for/in over an array unless you're certain you mean to iterate over non-numeric keys and inherited keys
*forEach() and for/in skip empty elements in the array, for and for/of do not
*you can't use await and yield within a forEach()

2)Stacks - last in first out(LIFO) | Abstract data type
Features - insertion(push) and deletion(pop) ONLY from top end and ONLY one element at a time with in O(1) time.
Implementation can be array or linked list based
Applications: function calls/recursion, undo operation, balanced parentheses, reverse operations
Array implementation - insertion/deletion of an element takes O(1) time but if array is full it takes O(n) time
Linked List implementation - insertion/deletion ONLY at head bcoz of O(1) time | insertion/deletion at tail takes O(n) time

3)Queues - first in first out(FIFO) | Abstract data type
Implementation can be array/ linked list
Enqueue and dequeue - O(1) and O(n) time respectively
Applications : if any resource can serve only one request at a time

4)Linked Lists: random memory allocation| for dealing with dynamic data (dynamic size)
Unlike arrays there will be no unused memory but extra memory needed for pointers.
Insert/delete/access: O(1) at first position | remaining positions : O(n)
No random access of element - u need to iterate the list till that element

//others
5)Sets

6)Hash Table/Hash Map
complexity on search,access,insertion and deletion - O(1)
map entries are unique

7)Trees - recursive data structure
terminology: root, nodes, leafs(nodes without children),internal nodes(nodes with atleast 1 child),link(connecting 2 nodes)
parent , children, siblings, ancestors, descendant, links are uni directional(parent to child)
tree with n nodes will have n-1 edges/links
applications: to represent hierarichal data(organisation info, family,file system), networking routing algorith, HTML DOM, quick search, insertion and deletion
depth of a node: no.of edges from root to that node
height of a node: no.of edges in the longest path from that node to leaf
height of a tree: height of root node (height of the tree with only one node 0, empty tree -1)
levels: root(level 0) 
max no of nodes at a given level: pow(2,i) 

**Binary Trees: each node has max 2 children 
Strict/proper Binary Tree: each node should have either 0 or 2 children 
complete/full Binary Tree: all the levels in a tree except the last one are completely filled and the nodes are as left as possible
perfect Binary Tree: all the levels in a tree are completely filled 
Balanced binary tree: for every node diff b/w height of left and right subtree shouldn't be more than k(mostly 1)
we always keep the tree height minimised so that the cost of operations that depend on height are less.
implementation: create nodes dynamically and link them using pointers
using arrays to store data (left link:2i+1, right link:2i+2) - only for complete binary tree

**Binary Search Trees : special kind of binary tree
defination - for each node value of all the nodes in left subtree is lesser/equal and value of all the nodes in right subtree is greater
insert/deletion/search - O(logn)
after insertion and deletion BST sometimes get unbalanced we need to re-balance it
while u search ur search space keeps on reducing from n->n/2->n/4.......1
n/2^k = 1 (k steps) | k= log2(n)
we should always keep the BST balanced so that the worst case complexity still remains O(log2(n))
else we need to iterate on all the nodes and the complexity will be O(n)

**tree traversal - visiting each node in the tree exactly once in some order
BFS - breadth first search (level order)
visiting all the nodes in the same level before moving to next level (root is level 0)
time complexity: O(n) | space complxity: O(n), best O(1)

DFS - depth first search (inorder, preorder, postorder)
visiting all the nodes in a subtree before moving to another subtree
preorder - root, left subtree, right subtree (subtrees are also visited in the same order)
inorder - left subtree, root, right subtree (left and right subtree traversal can be interchanged however conventionally left is visited first)
inorder traversal of a BST gives sorted list 
postorder - left subtree, right subtree ,root
time complexity: O(n) | space complxity: O(n) , best O(logn)

8)heaps - special kind of binary tree
9)Graphs
10)Trie - dictionary and recommendations


************************ ALGORITHMS **********************
ALGORITHMS = instructions given to computer to perform operations on data structures
algorithms are used depending on the data structure | some algorithms can be applied only to specific data structures
Every algorithm has a time and space complexity

//dynamic programming
memoization - re-use operation result by avoiding repeated computation on the same problems| The memoization technique is used in DP and it improves the performance of DP
DP is used to solve a larger subproblem given the solutions of smaller subproblem.
crux of dynamic programming is to find the optimal substructure in overlapping subproblems


**************** Big O Notation and Time Complexity *********
//Time Complexity - how does the time taken to run your function increases as the input size increases
Types of Complexity:
constant time O(1)
Logn time O(logN)
Linear time O(n)
quadratic time O(n^2)

//Space Complexity - 


********** TO IMPROVE *******
//problem solving skills

//Technical skills
1)Ds and algo
2)Read others code
3)Competitive programming: Freecodecamp and codecademy for practice
https://brilliant.org/CSDojo/
https://www.algoexpert.io/purchase
https://www.dailycodingproblem.com/
4)explore other Langs - node and python
5)build projects

//domain knowledge - also the impact ur work created in the bigger picture

//communication skills

