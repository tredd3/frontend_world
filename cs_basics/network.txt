//networking basics
https://www.cloudflare.com/en-in/learning/network-layer/what-is-a-computer-port/
A port is a virtual point where network connections start and end. Ports are software-based and managed by a computer's operating 
  system. Each port is associated with a specific process or service.
Most ports are reserved for certain protocols — for example, all Hypertext Transfer Protocol (HTTP) messages go to port 80. 
  While IP addresses enable messages to go to and from specific devices, port numbers allow targeting of specific services or
  applications within those devices.
  few more ports reserved are for services like http, ftp, smtp, dns, RDP etc
There are around 65535 ports. each port has a incoming and outgoing queue of messages
//These 65535 ports has been separated by the IANA (Internet Assigned Numbers Authority) into several different segments :
1)Port 0 is not used for internet/network traffic, but it’s sometimes utilized in communications going down between different programs on identical computers.
2)Ports 1-1023 are alluded to as system ports. These ports speak to official ports for most notable system administrations and many 
 common network services. HTTP usually communicates at port 80, while FTP at port 21. In most working frameworks/OS,
  administrative-level access is expected to begin a program that tunes in on a system port.
3)Ports 1024-49151 are known as registered ports. These ports are utilized for a bunch of different network functions and services 
  that probably won’t be very frequently used as ones that are on system ports.
4)port 49152-65535 - Ephemeral ports (or private ports) - for outbound network traffic and connections


/Input/output
Inputs are the signals or data received by the system and outputs are the signals or data sent from it. 
For instance, a keyboard or computer mouse is an input device for a computer, while monitors and printers are output devices
Devices for communication between computers, such as modems and network cards, typically perform both input and output operations.
**Any transfer of information to or from the CPU/memory combo, for example by reading data from a disk drive, is considered I/O
https://en.wikipedia.org/wiki/Input/output
IP address = network identifier + host indentifier
i.e, it is the address of a machine that is connected to the internet
subnet - logical subdivision of an IP network into two or more networks is called subnetting.
The Dynamic Host Configuration Protocol(DHCP) is a network management protocol used on Internet Protocol networks, whereby a 
DHCP server dynamically assigns an IP address and other network configuration parameters to each device on the network, 
so they can communicate with other IP networks
 A DHCP server enables computers to request IP addresses and networking parameters automatically from the Internet service provider (ISP), 
 reducing the need for a network administrator or a user to manually assign IP addresses to all network devices

//http vs https
HTTP provides standard rules for web browsers & servers to communicate.
HTTP is an application layer network protocol which is built on top of TCP.
HTTPS: It is a combination of SSL/TLS protocol and HTTP. 
Transport Layer Security/Secure Sockets Layer, are cryptographic protocols designed to provide communications security over a computer network
https://www.guru99.com/difference-http-vs-https.html
https://developer.mozilla.org/en-US/docs/Web/HTTP


https://www.youtube.com/watch?v=vv4y_uOneC0
//Open System Interconnection Model | OSI 7 layers
data is transferred from one computer through all the layers and decapsulated at another computer 
A - application layer - used by network applications like browser. They use proctocols of this layer
like ftp,HTTP,smtp,DNS (each protocol uses a specific port)
P - presentaion - receives data(numbers and characters) from application layer.
translation to binary then compression then encryption (SSL protocol) and decryption at receiver computer
S - session - Authentication, authorisation, session management
session layer keeps track of which data packet belongs to which file and which application
T - transport - segmentation, flow and error control
segmentation - break data into segments and each segment has sequence number(to rearrange), port number(to identify application)
flow/congestion control - client tells server at what rate data transfer should happen so that client can process it and data is not lost
error control - corrupted(using checksum) and missing(using segment numbers) data are requested again 
TCP(www, email,ftp) and UDP protocols(songs,movies,games) - Ports are a transport layer (layer 4) concept. Only a transport protocol
  such as the Transmission Control Protocol (TCP) or User Datagram Protocol (UDP) can indicate which port a packet should go to. 
  TCP and UDP headers have a section for indicating port numbers.
connection vs connection LESS
more packet size vs less packet size
slow vs fast
stream oriended(tcp splits data in chunks and recompose them) vs message oriented(application sends data in chunks)
reliable(all data is sent and that too in correct order) vs unreliable (random display of messages)
acknowledgment and re-transmission  vs no-acknowledgment
TCP usage: send text messages, file, image transfers, important information 
 Note: TCP traffic needs one destination port and one source port to establish a connection. At the point when a client needs to 
  speak with a server, the client will be appointed an ephemeral port to be utilized for simply that one connection, while the 
  server tunes in on a static system framework or registered port.
UDP usage: multimedia streaming

N - network - logical/ip adressing, routing, path determination
each segment is added with sender and destination ip address and the whole thing is called packet
routing - based on ip addressing + mask
path determination - uses the shortest path detemination protocols
D - data link - data unit in this layer is called frame. head consisits of souce and destination MAC address and tail is used for errors
media access control - this layer keeps an eye on shared media(ethernet/wifi) and once it is free it provides access to media to higher layers of OSI
physical addressing (mac address present in NIC)
Network interface controller(NIC) is a computer hardware component that connects a computer to a computer network
P - physical - Binary data is converted into signals depending on the media (electrical signals for LAN, radio waves for wifi, light waves for optical fiber)


//Network Requests
ASCII characters - Codes 0 through 127 (all keyboard chars)
NON ASCII characters - Codes 128 through 255
https://dev.to/sidthesloth92/understanding-html-form-encoding-url-encoded-and-multipart-forms-3lpa
x-www-form-urlencoded - to send simple text/ ASCII data to server with URL encoding
multipart/form-data - to send non-ASCII text or blob data like files and image uploading
Text/plain Forms - same as the URL encoded forms, except that the form fields are not URL encoded when sent to the server
Raw - if you want to send plain text /JSON/XML
Binary - non-textual data to the request, e.g. a video/audio file, images, or any other binary data file


// SERVER INTERACTION
By default,�HTTP�uses�port�80 and HTTPS uses�port�443
AJAX  uses XHR object and AJAX is used for partial page updates without full refresh.
AJAX - the process establishing a connection, sending request to server , getting the response and then updating the DOM
Fetch API - �Fetch API uses Promises, which enables a simpler and cleaner API, avoiding callback hell
API�stands for Application Programming Interface. It makes it possible to transfer data from an application to other applications.


//encoding vs encryption vs compression
*Encoding - Encoding is for maintaining data usability and can be reversed by employing the same algorithm that encoded the content,
 i.e. no key is used for reducing the size of audio and video files
Example: ASCII, BASE64, gzip 
*Encryption - maintaining data confidentiality and requires the use of a key (kept secret) to read it
*Compression - reduce the size of the data representation (gzip)
what is ASCII?  American Standard Code for Information Interchange, is a character encoding standard
The ASCII table has 128 characters, with values from 0 through 127.
Thus, 7 bits are sufficient to represent a character in ASCII; however, most computers typically reserve 1 byte, (8 bits), for an ASCII character.

**What is Base 64 Encoded Data? for sending binary data over text based protocol like HTTP
Base64 has 64 chars with values from 0 through 63 - each char represented by 6 bits
base64 encoded data is a string of character that contains only a-z, A-Z, 0-9, + and / characters and is often used in 
situations when sending non-text information(image,video and audio) via a text only transmission protocol.
The plain ASCII text includes a-z, A-Z, 0-9, ", %, &, ', (, ), *, +, -, _ and , (the comma). They will be referred to as the universal ASCII character set.
when trying to send e-mails in non English languages. Often these languages will have characters that are not part of the ASCII set.
 What is needed is a method to convert non-universal ASCII characters to a common form. This common form is called Base64 encoding.
**What does Base 64 Encoding Do?
https://www.youtube.com/watch?v=8qkxeZmKmOY
characters to numbers(from ASCII table) - each number to 8 bits - 6bits each are resolved to chars(base64 table)
e.g HEY(input) -> 72 101 121 -> 8bits 8 bits 8 bits -> SGV5(base64 encoded output)
3 chars in a srting are parsed at once to create a 4 char base64 encoded string.if it falls short special chars are added.
3*8=4*6

//character set and character encoding (how many bits to use to represent the number)
Unicode/ASCII is a character set. Character sets translates characters to numbers.
The first 128 characters of Unicode (which correspond one-to-one with ASCII)
UTF-8/base64 is encoding. UTF-8 Encoding translates numbers into binary. 
Base64 is a method to encode a byte sequence to a string
The Unicode Standard covers (almost) all the characters, punctuations, and symbols in the world.
Unicode enables processing, storage, and transport of text independent of platform and language.
The default character encoding in HTML-5 and web is UTF-8.

//javascript encoding and decoding methods
btoa() encodes a string of binary data in base-64 format. The most common use of this is for creating a data: URI 
from the contents of a file (e.g. turning a JPEG or GIF file into a data: URI that you incorporate directly into the page 
instead of referencing a remote file).

atob() performs the opposite: given a base-64 string, it returns the binary data.

encodeURIComponent() is used to perform URL-encoding of strings that will be used in a URI. This converts characters that have special meaning in URIs into % followed by the hex encoding, e.g. space becomes %20. This is usually used when creating URL parameters that will be used in redirects or AJAX requests, or the data that will be sent in XMLHTTPRequest.send().

decodeURIComponent() performs the reverse of encodeURIComponent(), so if you have "foo%20bar" it will return "foo bar".


********* HTTP ***********
//overview 
*application-layer protocol  for communication between web browsers and web servers,
application layer protocol that is sent over TCP, or over a TLS-encrypted TCP connection
*HTTP is a stateless protocol, meaning there is no link between two requests being successively carried out on the same connection
i.e any 2 requests are completely independent of each other.
*HTTP is connection less - after making a request client disconnects from server and when the response is ready
the connection is re-established and the response is delivered.
*Between the Web browser and the server, numerous computers and machines like proxies, modem and routers
*HTTP is simple(human readable messages), extensible(simple agreement between a client and a server about a new header's semantics),
stateless, but not sessionless - HTTP cookies allow the use of stateful sessions
*Though HTTP doesn't require the underlying transport protocol to be connection-based; only requiring it to be reliable, or not lose messages
TCP is reliable and UDP isn't. HTTP therefore relies on the TCP standard, which is connection-based
*HTTP flow: Open a TCP connection, Send an HTTP message, client disconnects, after response is ready,
connection re-established by the server and the response is sent. Close or reuse the connection for further requests
*both XHR and Fetch API are based on HTTP
*headers convey additional information to browsers/servers.
*features controllable with HTTP: caching, origin constraint, Authentication(authentication header and cookie),
sessions(cookies),Proxy and tunneling, compression


//HTTP Headers
HTTP message format: start line(method+target_url+version) + headers + body (for both request and response)
General headers apply to both requests and responses, but with no relation to the data transmitted in the body.
Request headers contain more information about the resource to be fetched, or about the client requesting the resource.
Response headers hold additional information about the response, like its location or about the server providing it.
Entity headers contain information about the body of the resource, like its content length or MIME type.
body is not sent in requests fetching resources, like GET, HEAD, DELETE, or OPTIONS
Some requests send data to the server in order to update it: POST,PUT requests
End-to-end headers
These headers must be transmitted to the final recipient of the message: the server for a request, or the client for a response. Intermediate proxies must retransmit these headers unmodified and caches must store them.
Hop-by-hop headers
These headers are meaningful only for a single transport-level connection, and must not be retransmitted by proxies or cached
Accept-Charset - Which character encodings the client understands.
Accept-Encoding - The encoding algorithm that can be used on the resource sent back.
**Message body information
Content-Length(bytes), Content-Type and Content-Encoding
Via general header is added by proxies, both forward and reverse proxies


//HTTP Request Methods
GET -  retrieve data, cacheable
HEAD - identical to that of a GET request, but without the response body.
Such a request can be done before deciding to download a large resource to save bandwidth by reading Content-Length header
for invalidating cache if we are not sure of how frequent the resource on the server changes
POST - sends data to the server. The type of the body of the request is indicated by the Content-Type header.
application/x-www-form-urlencoded: the keys and values are encoded in key-value tuples separated by '&', with a '=' between the key and the value.
 Non-alphanumeric characters in both keys and values are percent encoded: 
this is the reason why this type is not suitable to use with binary data (use multipart/form-data instead)
multipart/form-data: each value is sent as a block of data ("body part"), with a user agent-defined delimiter ("boundary") separating each part. 
The keys are given in the Content-Disposition header of each part.
text/plain
PUT - replaces all current representations of the target resource with the request payload.
DELETE - deletes the specified resource.
CONNECT - establishes a tunnel to the server identified by the target resource.
proxy servers might need authority to create a tunnel. we can Proxy-Authorization header.
OPTIONS - used to describe the communication options for the target resource.
used for preflight, load balancing and security.
TRACE - performs a message loop-back test along the path to the target resource.
PATCH - used to apply partial modifications to a resource.


//HTTP status Codes
200 - success
301 - moved permanently
302 - resource requested has been temporarily moved to the URL given by the Location header. A browser redirects to 
  this page but search engines don't update their links to the resource 
304 - not modified
307 (Temporary Redirect) and 308 (Permanent Redirect)
The Location response header indicates the URL to redirect a page to
4** - client error
400 - bad request
401 - unauthorised (not autheniticated)
The WWW-Authenticate header is sent along with a 401 Unauthorized response.
It defines the authentication method that should be used to gain access to a resource.
WWW-Authenticate: <type> realm=<realm>
403 - forbidden (unauthorised)
404 - not found
5** - server error
500 - Internal Server Error
501 - Not Implemented
502 - Bad Gateway
504 - Gateway Timeout

//Evolution of HTTP
**HTTP/1.1
currently browsers open up to 6 parallel connections under HTTP/1.1
open a separate TCP connection for each HTTP request/response pair
gzip compression used compresses body and not headers

**HTTP/2 - compression of headers , multiplexing ,encrypted data transfer, and push service
HTTP messages (before HTTP/2) are human-readable. With HTTP/2, these simple messages are encapsulated in
 frames, making them impossible to read directly, allowing optimizations like compression of headers and multiplexing.
still we need to use gzip compression for body | for http2 to work TLS has to be enabled
HTTP/2 introduces an extra step: it divides HTTP/1.x messages into frames which are embedded in a stream.
Data and header frames are separated, this allows header compression. Several streams can be combined together,
a process called multiplexing, allowing more efficient underlying TCP connections.
multiplexing allows your Browser to fire off multiple requests at once on the same connection and receive the responses back in any order
*by default every request starts as a HTTP/1 and gets upgraded to HTTP/2 if the client supports this upgraded protocol
*HTTP2 push - sending data for requests which are not made yet
like requesting index.html to server also pushes css and js in the response
now if the browser actually makes a request for css/js it is served from cache, reducing load time
*most of the browsers , web servers and programming languages have already implemented it.
*The client starts an HTTP/1.1 connection and sends an Upgrade: h2c header. If the server supports
 HTTP/2, it replies with HTTP 101 Switching Protocol status code.

**HTTP/3
will use QUIC(reliable UDP) instead TCP/TLS for the transport layer portion.

//HTTP caching - only GET requests
Private browser caches - specific to a user browser (preferred)
Shared proxy caches - popular resources are reused a number of times
Cache-Control: no-store //No caching
Cache-Control: no-cache //Cache but revalidate
pragma same as Cache-Control: no-cache, if the Cache-Control header field is omitted in a request. Use Pragma only for backwards compatibility with HTTP/1.0 clients
Cache-Control: public //response may be cached by any cache
Cache-Control: private //intended for a single user only and must not be stored by a shared cache
Cache-Control: max-age=31536000 //expiration
Cache-Control: must-revalidate //must verify the status of the stale resources before using it and expired ones should not be used
**freshness of cache
Cache-Control: "max-age=<seconds>"(relative to the time of the request) and EXPIRES header (random date and time)
cache validation - when the cache receives a request for a stale resource
it forwards this request with a If-None-Match request header with Etag value from previous request
if If-None-Match header value matches the Etag value at server then 304 not modified is sent else new response is sent
If-Modified-Since request header and Last-Modified response header
to check if it is in fact still fresh. If so, the server returns a 304 (Not Modified) header without sending the body of the requested resource, saving some bandwidth.
if neither header is present, look for a Last-Modified header
** serving content dynamically
When using the Vary: User-Agent header, caching servers should consider the user agent when deciding whether to serve the page from cache.
Because the User-Agent header value is different ("varies") for mobile and desktop clients, 
caches will not be used to serve mobile content mistakenly to desktop users or vice versa.


//HTTP Authentication
for server authentication:
WWW-Authenticate response header and Authorization request header
for proxy-server authentication:
Proxy-Authenticate response header and Proxy-Authorization request header
WWW-Authenticate: <type> realm=<realm>
Proxy-Authenticate: <type> realm=<realm>
<type> is the authentication scheme ("Basic" / "Bearer"). 
The realm is used to describe the protected area or to indicate the scope of protection.
Authorization: <type> <credentials>
Proxy-Authorization: <type> <credentials>
*Basic (base64-encoded username.password hence not secure) use it with https
we need to store the username and password somehow, in case they want to keep the user logged in after closing the app. 
You don’t want to store plaintext passwords, even on the client-side, as this can be exploited by XSS or CSRF
*Bearer (bearer tokens to access OAuth 2.0-protected resources)
let uname and pword be in the db. send POST request with username and password and get a token.
//if The token is randomly generated then it is mapped to the user in the central server (maintaining state) 
But in a distributed multiple-server environment, like a microservices architecture all the individual servers 
need to communicate with the central server.
//hence instead of using random tokens we use JWT which is cryptographically signed by server and
consists of info like user id and data so that multiple servers can decrypt and use the data instead of
asking central server about the user
The token can be invalidated without changing the password.
a single user can have multiple tokens ( one for the mobile app, another for the desktop app)


//FETCH API
1)fetch() allows you to make network requests similar to XMLHttpRequest (XHR) but Fetch API uses Promises, avoiding callback hell 
The response of a fetch() request is a Stream object, use the json() method to convert it into json
2)Timeouts Are Not Supported - request will continue for as long as the browser chooses.
function fetchTimeout(url, init, timeout = 3000) {
  return new Promise((resolve, reject) => {
    fetch(url, init)
      .then(resolve)
      .catch(reject);
    setTimeout(reject, timeout);
  }
}
Promise.race([
  fetch('http://url', { method: 'GET' }),
  new Promise(resolve => setTimeout(resolve, 3000))
])
3)cookies byfault don't go in a fetch request unlike XHR
4)Surprisingly, an HTTP error such as a 404 Page Not Found or 500 Internal Server Error does
 not cause the Fetch Promise to reject
5)abort the fetch request 
const controller = new AbortController();
Fetch can be aborted by calling controller.abort();
6)IE doesn't suppor fetch it needs a polyfill
**fetch modes
1)same-origin only succeeds for requests for assets on the same origin, all other requests will reject.
2)cors will allow requests for assets on the same-origin and other origins which return the appropriate CORs headers.
cors response restricts the headers you can view to `Cache-Control`, `Content-Language`, `Content-Type`, `Expires`, `Last-Modified`, and `Pragma`.
3)cors-with-forced-preflight will always perform a preflight check before making the actual request.
4)no-cors is intended to make requests to other origins that do not have CORS headers and result in an opaque response(u can't view),
 but as stated, this isn't possible in the window global scope at the moment but servie workers suopport


//Cross-Origin Resource Sharing (CORS)
In CORS, a preflight request with the OPTIONS method is sent, so that the server can respond whether it
 is safe to send the request with these parameters or is the server ready to accept the request at this point
Access-Control-Request-Method header notifies the server as part of a preflight request that when the 
actual request is sent, it will be sent with a POST request method. The Access-Control-Request-Headers
The server responds with Access-Control-Allow-Origin, Access-Control-Allow-Methods, Access-Control-Allow-Headers
Access-Control-Max-Age gives the value in seconds for how long the response to the preflight request can be cached for without sending another preflight request


//JSONP stands for JSON with Padding
Requesting a file from another domain using XHR can cause problems, due to cross-domain policy. 
Requesting an external script from another domain does not have this problem.
JSONP uses this advantage, and request files using the script tag instead of the XHR object.


//IFRAME
An inline frame is used to embed another document within the current HTML document.
like embedding a google map and youtube video
iframe to main window communication is via post message

//same origin policy - only for js files
prevents scripts from one origin to access private data on another origin
e.g: once u open fb in a browser window fb scripts cannot access resources from google server
unless it allows it using allow-access-control-origin header

//Data serialization
Data serialization is the process of translating data structures or object state into a format that can be stored or transmitted and reconstructed later.
e.g: JSON.stringify() for serialization and JSON.parse() for de-serialization
