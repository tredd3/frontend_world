//OS basics
An operating system is a program that acts as an interface between the software and the computer hardware.
user - software applications - OS - hardware
It is an integrated set of specialized programs used to manage overall resources, controls and monitors the execution 
of all other programs that reside in the computer (whether applications or system software)

Memory Management − Keeps track of the primary memory, i.e. what part of it is in use by whom, what part is not in use, etc. and allocates the memory when a process or program requests it.
Processor Management − Allocates the processor (CPU) to a process and deallocates the processor when it is no longer required.
Device Management − Keeps track of all the devices. This is also called I/O controller that decides which process gets the device, when, and for how much time.
File Management − Allocates and de-allocates the resources and decides who gets the resources.
Security − Prevents unauthorized access to programs and data by means of passwords and other similar techniques.

Job Accounting

process:
A program in execution is known as Process
Process memory consists of: stack+heap+data(global and static variables)+text(compiled code)
Thread: 
https://www.geeksforgeeks.org/thread-in-operating-system/
A thread is a path of execution within a process. A process can contain multiple threads.
Multithreading: achieve parallelism by dividing a process into multiple threads
threads within the same process run in a shared memory space, while processes run in separate memory spaces.
Threads are not independent of one another like processes and hence share code section, data section, and
 OS resources (like open files and signals)
But, like process, a thread has its own program counter (PC), register set, and stack space.
A program counter is a register in a computer processor that contains the address (location) of the instruction being 
executed at the current time.

Paging:
Paging is a memory management scheme that eliminates the need for contiguous allocation of physical memory to a process
Logical Address or Virtual Address (represented in bits): An address generated by the CPU
The mapping from virtual to physical address is done by the memory management unit (MMU) which is a hardware device and 
this mapping is known as paging technique.

CPU scheduler:
It selects a process among the processes that are ready to execute and allocates CPU to one of them.

DEADLOCK:
A process in operating systems uses different resources and uses resources in following way.
1) Requests a resource
2) Use the resource
2) Releases the resource
**Deadlock can arise if following four conditions hold simultaneously (Necessary Conditions): 
Mutual Exclusion: One or more than one resource are non-sharable (Only one process can use at a time) 
Hold and Wait: A process is holding at least one resource and waiting for resources.
No Preemption: A resource cannot be taken from a process unless the process releases the resource.
Circular Wait: A set of processes are waiting for each other in circular form
It can be prevented by avoiding the necessary conditions for deadlock

STARVATION:
High priority processes keep executing and low priority processes are blocked for indefinite time
Resources are continuously utilized by high priority processes
It can be prevented by Aging. In Aging priority of long waiting processes is gradually increased.

Kernel: 
https://en.wikipedia.org/wiki/Kernel_(operating_system)
The kernel is a computer program at the core of a computer's operating system with complete control over everything in the system
A kernel is a interface between the applications(browser,audio and video player etc) and hardware of a computer.
2 types of kernels:
Monolithic kernel is a single large process running entirely in a single address space.
In microkernels, the kernel is broken down into separate processes, known as servers.
Some of the servers run in kernel space and some run in user-space. 
https://www.geeksforgeeks.org/introduction-of-system-call/ 
System call provides the services of the os kernel to the user programs via Application Program Interface(API). 

Concurrency vs Parallelism
//Concurrency : multiple threads are making progress concurrently. While only one thread 
is executed at a time by the CPU, these threads can be switched in and out as required.
 This means that no thread is actually completed totally before another is scheduled. 
cores used: single core
javascript/node handles concurrency via event loop 
//Parallelism : multiple processes are making progress in parallel.
This means that the threads are executing at the same time on parallel processors.
cores used: multiple cores
javascript/node handles parallelism via web workers

mutex vs semaphore
mutual exclusion(mutex) is a property of concurrency control, which is instituted for the purpose of preventing race conditions.
e.g:
Consider the standard producer-consumer problem. Assume, we have a buffer of 4096 byte length. A producer thread collects the data 
and writes it to the buffer. A consumer thread processes the collected data from the buffer. Objective is, both the threads should not run at the same time.
Using Mutex:
A mutex provides mutual exclusion, either producer or consumer can have the key (mutex) and proceed with their work. As long as the 
buffer is filled by producer, the consumer needs to wait, and vice versa.
At any point of time, only one thread can work with the entire buffer.
Using Semaphore:
A semaphore is a generalized mutex. In lieu of single buffer, we can split the 4 KB buffer into four 1 KB buffers (identical resources).
A semaphore can be associated with these four buffers. The consumer and producer can work on different buffers at the same time.

//LINUX vs UNIX
https://www.guru99.com/difference-unix-vs-linux.html