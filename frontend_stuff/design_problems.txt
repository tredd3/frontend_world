//terminologies
**scalability - handling huge number of requests
1)vertical scalability - increase the current system's computation power, memory, RAM 
time taken to process a request is reduced
single point of failure
inter process communication as there is only server
data consistency
2)horizontal scalability - increase the total number of servers
load balancer is needed
if one of the server fails there are other servers to bank on
network communication b/w servers


//approach


//design whatsapp


//design twiter

//building large applications that can scale
1)client side
web performance - loading + rendering performance
react


2)server side
microservice - decoupling
CDN - caching, reduce latency 
caching - eviction policy needs to be good like LRU and it should have large size else extra call to cache, 
cache invalidation
background sync - update ur cache first and then after every 10sec sync ur updated cache with db in a single request
but keep a list of updated keys so that after 10sec u go and update the data corresponding to keys in ur db
load balancing - distribute load between servers (round robin, weighted round robin, least connections,
weighed least connections, URL Hash and least latency), consistent hashing
Least latency - makes a quick HTTP OPTIONS request to backend servers, and sends the request to the first server to answer
//Consistent hashing assigns requests to the servers in a way that the load is equally balanced on servers
Consistent Hashing maps servers to the key space and assigns requests to the next clockwise server
M hash fns and N servers - servers are placed at N*M points
2 principles allowed by Consistent Hashing - fault tolerance(removing servers), scalability (adding servers)
cloud - large computing 
kafka - messaging queue - large real time data is split into multiple buckets and then passed into UI after
some time which avaoids flickering and http querying overhead at the UI end.
polling - using background thread for making request after every x sec to get new data like feed/ 
to tell if a person is online or not 
long polling - make a request and keep connection open until new data comes 
polling and long polling are used as backward compatibility to web sockets 
websockets - for full duplex communication (sending and recieving data at the same time over same connection)

3)databases
sharding - split ur database - useful for microservice architecture
vertical sharding - put each table in a new machine so that the requests get split
machine1 - user profile requests will go to this machine
machine2 - user cart table requests will go to this machine
horizontal sharding - split a single table and put it into multiple machines (based on time/userid/geography)
machine1 - user profile table(indian profile) - request from india will be routed to machine1
machine2 - user profile table(american profiles) - request from america will be routed to machine2
apply indexing on a horizontally sharded table
//To reduce load on main db server
1)in memory caching - reddis, memcache
2)master-slave architecture
all read operations from slaves
all write operations to master and sync master with slaves

whatsapp - https://www.youtube.com/watch?v=vvhC64hQZMk
parking lot - https://www.youtube.com/watch?v=DSGsa0pu8-k
uber - https://www.youtube.com/watch?v=umWABit-wbk
